# ROCmç’°å¢ƒè¨­å®š
import os
os.environ['HSA_OVERRIDE_GFX_VERSION'] = '10.3.0'  # æ ¹æ“šä½ çš„GPUèª¿æ•´
os.environ['HIP_VISIBLE_DEVICES'] = '0'

# åŸºæœ¬å¥—ä»¶å°å…¥
import torch
import numpy as np
from transformers import pipeline, AutoProcessor, AutoModelForSpeechSeq2Seq
import soundfile as sf
import subprocess
import tempfile
from pydub import AudioSegment
import librosa
import torchaudio
from torchaudio.transforms import Resample

# global varivbles

device = 0

def check_tools():
    try:
        import ChatTTS
        print("âœ… ChatTTSå°å…¥æˆåŠŸ")
    except ImportError:
        print("âŒ ChatTTSæœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install ChatTTS")
        ChatTTS = None


    # å˜—è©¦å°å…¥å°ç£è¨€èªå·¥å…·
    try:
        from è‡ºç£è¨€èªå·¥å…· import èªéŸ³åˆæˆ
        from è‡ºç£è¨€èªå·¥å…· import èªéŸ³è¾¨è­˜
        print("âœ… å°ç£è¨€èªå·¥å…·å°å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ å°ç£è¨€èªå·¥å…·å°å…¥å¤±æ•—: {e}")
        èªéŸ³åˆæˆ = None
        èªéŸ³è¾¨è­˜ = None
    
def check_rocm_environment():
    """æª¢æŸ¥ROCmç’°å¢ƒ"""
    print("=== ROCmç’°å¢ƒæª¢æŸ¥ ===")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"ROCmå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPUæ•¸é‡: {torch.cuda.device_count()}")
        print(f"ç•¶å‰GPU: {torch.cuda.current_device()}")
        print(f"GPUåç¨±: {torch.cuda.get_device_name()}")
    print("==================")

def setup_device():
    """è¨­å®šè¨ˆç®—è¨­å‚™"""
    if torch.cuda.is_available():
        _device = "cuda"
        print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
    else:
        _device = "cpu"
        print("âš ï¸ ä½¿ç”¨CPUï¼ˆå»ºè­°ä½¿ç”¨GPUåŠ é€Ÿï¼‰")

    torch.set_default_device(_device)
    return _device

def convert_windows_path(path):
    """è½‰æ›Windowsè·¯å¾‘ç‚ºWSLè·¯å¾‘"""
    if path.startswith('C:'):
        return path.replace('C:', '/mnt/c').replace('\\', '/')
    return path


def resample_audio_to_16khz(waveform, original_sample_rate, target_rate=16000):
    """å°‡éŸ³æª”é‡æ–°æ¡æ¨£åˆ°16kHz"""
    
    if original_sample_rate == target_rate:
        print(f"âœ… æ¡æ¨£ç‡å·²æ˜¯ {target_rate}Hzï¼Œç„¡éœ€é‡æ–°æ¡æ¨£")
        return waveform, target_rate
    
    print(f"ğŸ”„ é‡æ–°æ¡æ¨£: {original_sample_rate}Hz â†’ {target_rate}Hz")
    
    # æ–¹æ³•1: ä½¿ç”¨librosaé‡æ–°æ¡æ¨£ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    try:
        if librosa:
            if len(waveform.shape) > 1 and waveform.shape[0] > 1:
                # å¤šè²é“è™•ç†
                resampled = []
                for channel in waveform:
                    channel_resampled = librosa.resample(
                        channel.numpy(), 
                        orig_sr=original_sample_rate, 
                        target_sr=target_rate
                    )
                    resampled.append(channel_resampled)
                waveform_resampled = torch.from_numpy(np.array(resampled))
            else:
                # å–®è²é“è™•ç†
                waveform_np = waveform.squeeze().numpy()
                waveform_resampled_np = librosa.resample(
                    waveform_np, 
                    orig_sr=original_sample_rate, 
                    target_sr=target_rate
                )
                waveform_resampled = torch.from_numpy(waveform_resampled_np).unsqueeze(0)
            
            print(f"âœ… librosaé‡æ–°æ¡æ¨£æˆåŠŸ")
            return waveform_resampled, target_rate
    except Exception as e:
        print(f"âš ï¸ librosaé‡æ–°æ¡æ¨£å¤±æ•—: {e}")
    
    # æ–¹æ³•2: ä½¿ç”¨torchaudioé‡æ–°æ¡æ¨£
    try:
        resampler = Resample(orig_freq=original_sample_rate, new_freq=target_rate)
        waveform_resampled = resampler(waveform)
        print(f"âœ… torchaudioé‡æ–°æ¡æ¨£æˆåŠŸ")
        return waveform_resampled, target_rate
    except Exception as e:
        print(f"âš ï¸ torchaudioé‡æ–°æ¡æ¨£å¤±æ•—: {e}")
    
    # æ–¹æ³•3: ä½¿ç”¨ffmpegé‡æ–°æ¡æ¨£
    try:
        import tempfile
        import subprocess
        
        # å„²å­˜åŸå§‹éŸ³æª”
        temp_input = tempfile.mktemp(suffix='.wav')
        torchaudio.save(temp_input, waveform, original_sample_rate)
        
        # ä½¿ç”¨ffmpegé‡æ–°æ¡æ¨£
        temp_output = tempfile.mktemp(suffix='.wav')
        subprocess.run([
            'ffmpeg', '-i', temp_input, 
            '-ar', str(target_rate), 
            '-ac', '1',  # è½‰ç‚ºå–®è²é“
            temp_output, '-y'
        ], check=True, capture_output=True)
        
        # è¼‰å…¥é‡æ–°æ¡æ¨£å¾Œçš„éŸ³æª”
        waveform_resampled, _ = torchaudio.load(temp_output)
        
        # æ¸…ç†æš«å­˜æª”
        os.remove(temp_input)
        os.remove(temp_output)
        
        print(f"âœ… ffmpegé‡æ–°æ¡æ¨£æˆåŠŸ")
        return waveform_resampled, target_rate
    except Exception as e:
        print(f"âŒ ffmpegé‡æ–°æ¡æ¨£å¤±æ•—: {e}")
    
    raise RuntimeError(f"ç„¡æ³•é‡æ–°æ¡æ¨£éŸ³æª”å¾ {original_sample_rate}Hz åˆ° {target_rate}Hz")


def ensure_16khz_for_whisper(waveform, sample_rate):
    """ç¢ºä¿éŸ³æª”ç¬¦åˆWhisperçš„16kHzè¦æ±‚"""
    
    print(f"ğŸµ æª¢æŸ¥æ¡æ¨£ç‡: {sample_rate}Hz")
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°æ¡æ¨£
    if sample_rate != 16000:
        print(f"âš ï¸ æ¡æ¨£ç‡ {sample_rate}Hz ä¸ç¬¦åˆWhisperè¦æ±‚ï¼Œé‡æ–°æ¡æ¨£åˆ°16kHz")
        waveform, sample_rate = resample_audio_to_16khz(waveform, sample_rate)
    
    # ç¢ºä¿æ˜¯å–®è²é“
    if len(waveform.shape) > 1 and waveform.shape[0] > 1:
        print("ğŸ”„ è½‰æ›ç‚ºå–®è²é“")
        waveform = torch.mean(waveform, dim=0, keepdim=True)
    
    print(f"âœ… éŸ³æª”æº–å‚™å®Œæˆ: æ¡æ¨£ç‡={sample_rate}Hz, å½¢ç‹€={waveform.shape}")
    return waveform, sample_rate

def load_audio_for_whisper(audio_path):
    """å°ˆç‚ºWhisperæ¨¡å‹è¼‰å…¥å’Œé è™•ç†éŸ³æª”"""
    
    print(f"ğŸµ ç‚ºWhisperè¼‰å…¥éŸ³æª”: {audio_path}")
    
    # ä½¿ç”¨ä¹‹å‰å»ºç«‹çš„å¤šé‡å‚™æ´è¼‰å…¥å‡½æ•¸
    waveform, sample_rate = load_audio_smart(audio_path)
    
    # ç¢ºä¿ç¬¦åˆWhisperè¦æ±‚
    waveform, sample_rate = ensure_16khz_for_whisper(waveform, sample_rate)
    
    return waveform, sample_rate

class TaiwaneseSTTTTSSystem:
    def __init__(self):
        """åˆå§‹åŒ–å°èªèªéŸ³è½‰æ›ç³»çµ±ï¼ˆROCmå„ªåŒ–ç‰ˆï¼‰"""
        self.device = device
        #self.setup_stt_model()
        #self.setup_tts_model()
        self.setup_taiwanese_tools()

    def setup_stt_model(self):
        
        """è¨­å®šå°èªè½‰ä¸­æ–‡çš„èªéŸ³è¾¨è­˜æ¨¡å‹"""
        try:
            # ä¿®æ­£æ¨¡å‹åç¨±
            model_name = "C:/Users\johns\models\whisper"

            self.stt_processor = AutoProcessor.from_pretrained(model_name)
            self.stt_model = AutoModelForSpeechSeq2Seq.from_pretrained(
                model_name,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                device_map="auto" if self.device == "cuda" else None
            )
            print(f"âœ… Whisper è¼‰å…¥æˆåŠŸï¼Œä½¿ç”¨è¨­å‚™ï¼š{self.device}")
        except Exception as e:
            print(f"âŒ MR Breeze ASRè¼‰å…¥å¤±æ•—ï¼Œæ”¹ç”¨Whisperï¼š{e}")
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨Whisper
            self.stt_pipe = pipeline(
                "automatic-speech-recognition",
                model="openai/whisper-medium",
                device=0 if self.device == "cuda" else -1
            )
            self.stt_model = None

    def setup_tts_model(self):
        """è¨­å®šä¸­æ–‡è½‰å°èªçš„èªéŸ³åˆæˆæ¨¡å‹ï¼ˆROCmå„ªåŒ–ï¼‰"""
        try:
            if ChatTTS:
                self.chattts = ChatTTS.Chat()

                # ROCmç’°å¢ƒè¨­å®š
                if self.device == "cuda":
                    self.chattts.load_models(
                        compile=False,
                        device="cuda",
                        dtype=torch.float16
                    )
                else:
                    self.chattts.load_models(compile=False)

                print("âœ… ChatTTSè¼‰å…¥æˆåŠŸ")
            else:
                raise ImportError("ChatTTSæœªå°å…¥")
        except Exception as e:
            print(f"âŒ ChatTTSè¼‰å…¥å¤±æ•—ï¼š{e}")
            self.chattts = None

    def setup_taiwanese_tools(self):
        """è¨­å®šå°ç£è¨€èªå·¥å…·"""
        try:
            if èªéŸ³åˆæˆ and èªéŸ³è¾¨è­˜:
                # æ­£ç¢ºå¯¦ä¾‹åŒ–é¡åˆ¥
                self.taiwanese_synthesizer = èªéŸ³åˆæˆ()
                self.taiwanese_recognizer = èªéŸ³è¾¨è­˜()
                print("âœ… å°ç£è¨€èªå·¥å…·è¼‰å…¥æˆåŠŸ")
            else:
                raise ImportError("å°ç£è¨€èªå·¥å…·æ¨¡çµ„æœªå°å…¥")
        except Exception as e:
            print(f"âŒ å°ç£è¨€èªå·¥å…·è¼‰å…¥å¤±æ•—: {e}")
            self.taiwanese_synthesizer = None
            self.taiwanese_recognizer = None
            

    def taiwanese_to_chinese_text(self, audio_file_path):
        try:
            print(f"ğŸ¤ é–‹å§‹èªéŸ³è¾¨è­˜: {audio_file_path}")
            
            # è™•ç†è·¯å¾‘
            
            # è¼‰å…¥ä¸¦ç¢ºä¿16kHzæ¡æ¨£ç‡
            waveform, sample_rate = torchaudio.load(audio_file_path)
            audio, sample_rate = ensure_16khz_for_whisper(waveform, sample_rate)
            
            print("Whisper èªéŸ³è™•ç†å®Œæˆ")
            model_name = "C:/Users\johns\models\whisper"

            pipe = pipeline("automatic-speech-recognition", model = model_name)

            result = pipe(audio, generate_kwargs={"language": "zh", "task": "transcribe"})
            text = result['text']
            
            print(f"ğŸ“ è¾¨è­˜å®Œæˆ: {text}")
            return text
            
        except Exception as e:
            print(f"âŒ èªéŸ³è¾¨è­˜éŒ¯èª¤: {e}")
            return None

    #def chinese_to_taiwanese_speech(self, chinese_text):
        

    def play_audio(self, audio_file):
        """æ’­æ”¾éŸ³æª”"""
        try:
            # åœ¨WSLç’°å¢ƒä¸­ä½¿ç”¨ç³»çµ±æ’­æ”¾å™¨
            audio_path = convert_windows_path(audio_file)
            subprocess.run(['aplay', audio_path], check=True)
        except Exception as e:
            print(f"âŒ æ’­æ”¾éŸ³æª”éŒ¯èª¤: {e}")
            print("ğŸ’¡ æç¤ºï¼šåœ¨WSLä¸­å¯èƒ½éœ€è¦å®‰è£éŸ³é »æ’­æ”¾å·¥å…·")

    def process_taiwanese_audio_pipeline(self, input_audio_file):
        """å®Œæ•´çš„å°èªéŸ³æª”è™•ç†æµç¨‹"""
        print("ğŸ™ï¸ é–‹å§‹è™•ç†å°èªéŸ³æª”...")

        # æ­¥é©Ÿ1: å°èªèªéŸ³è½‰ä¸­æ–‡æ–‡å­—
        chinese_text = self.taiwanese_to_chinese_text(input_audio_file)
        if chinese_text:
            print(f"ğŸ“ è¾¨è­˜çµæœ: {chinese_text}")
            return chinese_text
        else:
            print("âŒ èªéŸ³è¾¨è­˜å¤±æ•—")
            return

        # æ­¥é©Ÿ2: ä¸­æ–‡æ–‡å­—è½‰å°èªèªéŸ³
        '''output_file = self.chinese_to_taiwanese_speech(chinese_text)
        if output_file:
            print(f"ğŸ”Š èªéŸ³åˆæˆå®Œæˆ: {output_file}")

            # æ­¥é©Ÿ3: æ’­æ”¾åˆæˆçš„å°èªèªéŸ³
            self.play_audio(output_file)
        else:
            print("âŒ èªéŸ³åˆæˆå¤±æ•—")'''

def resample_audio_to_16khz(waveform, original_sample_rate, target_rate=16000):
    """å°‡éŸ³æª”é‡æ–°æ¡æ¨£åˆ°16kHz"""
    
    if original_sample_rate == target_rate:
        print(f"âœ… æ¡æ¨£ç‡å·²æ˜¯ {target_rate}Hzï¼Œç„¡éœ€é‡æ–°æ¡æ¨£")
        return waveform, target_rate
    
    print(f"ğŸ”„ é‡æ–°æ¡æ¨£: {original_sample_rate}Hz â†’ {target_rate}Hz")
    
    try:
        resampler = Resample(orig_freq=original_sample_rate, new_freq=target_rate)
        waveform_resampled = resampler(waveform)
        print(f"âœ… é‡æ–°æ¡æ¨£æˆåŠŸ")
        return waveform_resampled, target_rate
    except Exception as e:
        print(f"âŒ é‡æ–°æ¡æ¨£å¤±æ•—: {e}")
        raise

# ä¿®æ­£åŸæœ‰çš„load_audio_smartå‡½æ•¸
# original_load_audio_smart = load_audio_smart

def load_audio_smart(audio_path, target_sr=16000):
    """æ™ºèƒ½è¼‰å…¥éŸ³æª”ä¸¦é‡æ–°æ¡æ¨£ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    
    # ä½¿ç”¨åŸæœ‰çš„è¼‰å…¥å‡½æ•¸
    waveform, sample_rate = original_load_audio_smart(audio_path)
    
    # é‡æ–°æ¡æ¨£åˆ°ç›®æ¨™æ¡æ¨£ç‡
    if sample_rate != target_sr:
        waveform, sample_rate = resample_audio_to_16khz(waveform, sample_rate, target_sr)
    
    # ç¢ºä¿å–®è²é“
    if len(waveform.shape) > 1 and waveform.shape[0] > 1:
        print("ğŸ”„ è½‰æ›ç‚ºå–®è²é“")
        waveform = torch.mean(waveform, dim=0, keepdim=True)
    
    return waveform, sample_rate

# ä½¿ç”¨ç¯„ä¾‹ï¼ˆROCmå„ªåŒ–ç‰ˆï¼‰
def transform():
    # åˆå§‹åŒ–ç³»çµ±
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–å°èªèªéŸ³è½‰æ›ç³»çµ±ï¼ˆROCmç‰ˆï¼‰...")
    system = TaiwaneseSTTTTSSystem()

    # ç¯„ä¾‹1: è™•ç†å°èªéŸ³æª”
    #input_audio = "C:/Users/johns/taiwanese_voice/cv-corpus-22.0-delta-2025-06-20/nan-tw/clips/common_voice_nan-tw_42722929.mp3"
    input_audio = "C:/Users/johns/Desktop/project/2025meichu_hackathon/backend/speech_to_text/output.wav"
    chinese_text = system.process_taiwanese_audio_pipeline(input_audio)
    
    with open('C:/Users/johns/Desktop/project/2025meichu_hackathon/backend/example.txt', 'w', encoding='utf-8') as file:
        file.write(chinese_text)
    # ç¯„ä¾‹2: ç›´æ¥ä¸­æ–‡è½‰å°èª
    '''chinese_text = "ä½ å¥½ï¼Œä»Šå¤©å¤©æ°£å¾ˆå¥½"
    print(f"\nğŸ”„ è½‰æ›ä¸­æ–‡æ–‡å­—: {chinese_text}")
    output_file = system.chinese_to_taiwanese_speech(chinese_text, "direct_output.wav")
    if output_file:
        print(f"âœ… ç›´æ¥è½‰æ›æˆåŠŸ: {output_file}")
        system.play_audio(output_file)
    else:
        print("âŒ ç›´æ¥è½‰æ›å¤±æ•—")'''
        
def initial_setting():
    global device
    check_tools()
    check_rocm_environment()
    device = setup_device()
        