{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OrUHVL0_KQxi",
        "outputId": "33f813ab-6b66-4cc3-b363-c9154b303ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ ChatTTS導入成功\n",
            "❌ 台灣言語工具導入失敗: No module named '臺灣言語工具'\n"
          ]
        }
      ],
      "source": [
        "# ROCm環境設定\n",
        "import os\n",
        "os.environ['HSA_OVERRIDE_GFX_VERSION'] = '10.3.0'  # 根據你的GPU調整\n",
        "os.environ['HIP_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "# 基本套件導入\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import pipeline, AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "import soundfile as sf\n",
        "import subprocess\n",
        "import tempfile\n",
        "from pydub import AudioSegment\n",
        "import librosa\n",
        "\n",
        "try:\n",
        "    import ChatTTS\n",
        "    print(\"✅ ChatTTS導入成功\")\n",
        "except ImportError:\n",
        "    print(\"❌ ChatTTS未安裝，請執行: pip install ChatTTS\")\n",
        "    ChatTTS = None\n",
        "\n",
        "\n",
        "# 嘗試導入台灣言語工具\n",
        "try:\n",
        "    from 臺灣言語工具 import 語音合成\n",
        "    from 臺灣言語工具 import 語音辨識\n",
        "    print(\"✅ 台灣言語工具導入成功\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ 台灣言語工具導入失敗: {e}\")\n",
        "    語音合成 = None\n",
        "    語音辨識 = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "#source venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3DybdAxwKVWG",
        "outputId": "eed33ee3-d435-4357-b59f-740d70b6b74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ROCm環境檢查 ===\n",
            "PyTorch版本: 2.8.0+cpu\n",
            "ROCm可用: False\n",
            "==================\n",
            "⚠️ 使用CPU（建議使用GPU加速）\n"
          ]
        }
      ],
      "source": [
        "def check_rocm_environment():\n",
        "    \"\"\"檢查ROCm環境\"\"\"\n",
        "    print(\"=== ROCm環境檢查 ===\")\n",
        "    print(f\"PyTorch版本: {torch.__version__}\")\n",
        "    print(f\"ROCm可用: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU數量: {torch.cuda.device_count()}\")\n",
        "        print(f\"當前GPU: {torch.cuda.current_device()}\")\n",
        "        print(f\"GPU名稱: {torch.cuda.get_device_name()}\")\n",
        "    print(\"==================\")\n",
        "\n",
        "def setup_device():\n",
        "    \"\"\"設定計算設備\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "        print(f\"✅ 使用GPU: {torch.cuda.get_device_name()}\")\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "        print(\"⚠️ 使用CPU（建議使用GPU加速）\")\n",
        "\n",
        "    torch.set_default_device(device)\n",
        "    return device\n",
        "\n",
        "# 執行環境檢查\n",
        "check_rocm_environment()\n",
        "device = setup_device()\n",
        "\n",
        "def convert_windows_path(path):\n",
        "    \"\"\"轉換Windows路徑為WSL路徑\"\"\"\n",
        "    if path.startswith('C:'):\n",
        "        return path.replace('C:', '/mnt/c').replace('\\\\', '/')\n",
        "    return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import librosa\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio.transforms import Resample\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def resample_audio_to_16khz(waveform, original_sample_rate, target_rate=16000):\n",
        "    \"\"\"將音檔重新採樣到16kHz\"\"\"\n",
        "    \n",
        "    if original_sample_rate == target_rate:\n",
        "        print(f\"✅ 採樣率已是 {target_rate}Hz，無需重新採樣\")\n",
        "        return waveform, target_rate\n",
        "    \n",
        "    print(f\"🔄 重新採樣: {original_sample_rate}Hz → {target_rate}Hz\")\n",
        "    \n",
        "    # 方法1: 使用librosa重新採樣（如果可用）\n",
        "    try:\n",
        "        if librosa:\n",
        "            if len(waveform.shape) > 1 and waveform.shape[0] > 1:\n",
        "                # 多聲道處理\n",
        "                resampled = []\n",
        "                for channel in waveform:\n",
        "                    channel_resampled = librosa.resample(\n",
        "                        channel.numpy(), \n",
        "                        orig_sr=original_sample_rate, \n",
        "                        target_sr=target_rate\n",
        "                    )\n",
        "                    resampled.append(channel_resampled)\n",
        "                waveform_resampled = torch.from_numpy(np.array(resampled))\n",
        "            else:\n",
        "                # 單聲道處理\n",
        "                waveform_np = waveform.squeeze().numpy()\n",
        "                waveform_resampled_np = librosa.resample(\n",
        "                    waveform_np, \n",
        "                    orig_sr=original_sample_rate, \n",
        "                    target_sr=target_rate\n",
        "                )\n",
        "                waveform_resampled = torch.from_numpy(waveform_resampled_np).unsqueeze(0)\n",
        "            \n",
        "            print(f\"✅ librosa重新採樣成功\")\n",
        "            return waveform_resampled, target_rate\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ librosa重新採樣失敗: {e}\")\n",
        "    \n",
        "    # 方法2: 使用torchaudio重新採樣\n",
        "    try:\n",
        "        resampler = Resample(orig_freq=original_sample_rate, new_freq=target_rate)\n",
        "        waveform_resampled = resampler(waveform)\n",
        "        print(f\"✅ torchaudio重新採樣成功\")\n",
        "        return waveform_resampled, target_rate\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ torchaudio重新採樣失敗: {e}\")\n",
        "    \n",
        "    # 方法3: 使用ffmpeg重新採樣\n",
        "    try:\n",
        "        import tempfile\n",
        "        import subprocess\n",
        "        \n",
        "        # 儲存原始音檔\n",
        "        temp_input = tempfile.mktemp(suffix='.wav')\n",
        "        torchaudio.save(temp_input, waveform, original_sample_rate)\n",
        "        \n",
        "        # 使用ffmpeg重新採樣\n",
        "        temp_output = tempfile.mktemp(suffix='.wav')\n",
        "        subprocess.run([\n",
        "            'ffmpeg', '-i', temp_input, \n",
        "            '-ar', str(target_rate), \n",
        "            '-ac', '1',  # 轉為單聲道\n",
        "            temp_output, '-y'\n",
        "        ], check=True, capture_output=True)\n",
        "        \n",
        "        # 載入重新採樣後的音檔\n",
        "        waveform_resampled, _ = torchaudio.load(temp_output)\n",
        "        \n",
        "        # 清理暫存檔\n",
        "        os.remove(temp_input)\n",
        "        os.remove(temp_output)\n",
        "        \n",
        "        print(f\"✅ ffmpeg重新採樣成功\")\n",
        "        return waveform_resampled, target_rate\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ffmpeg重新採樣失敗: {e}\")\n",
        "    \n",
        "    raise RuntimeError(f\"無法重新採樣音檔從 {original_sample_rate}Hz 到 {target_rate}Hz\")\n",
        "\n",
        "\n",
        "def ensure_16khz_for_whisper(waveform, sample_rate):\n",
        "    \"\"\"確保音檔符合Whisper的16kHz要求\"\"\"\n",
        "    \n",
        "    print(f\"🎵 檢查採樣率: {sample_rate}Hz\")\n",
        "    \n",
        "    # 檢查是否需要重新採樣\n",
        "    if sample_rate != 16000:\n",
        "        print(f\"⚠️ 採樣率 {sample_rate}Hz 不符合Whisper要求，重新採樣到16kHz\")\n",
        "        waveform, sample_rate = resample_audio_to_16khz(waveform, sample_rate)\n",
        "    \n",
        "    # 確保是單聲道\n",
        "    if len(waveform.shape) > 1 and waveform.shape[0] > 1:\n",
        "        print(\"🔄 轉換為單聲道\")\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "    \n",
        "    print(f\"✅ 音檔準備完成: 採樣率={sample_rate}Hz, 形狀={waveform.shape}\")\n",
        "    return waveform, sample_rate\n",
        "\n",
        "def load_audio_for_whisper(audio_path):\n",
        "    \"\"\"專為Whisper模型載入和預處理音檔\"\"\"\n",
        "    \n",
        "    print(f\"🎵 為Whisper載入音檔: {audio_path}\")\n",
        "    \n",
        "    # 使用之前建立的多重備援載入函數\n",
        "    waveform, sample_rate = load_audio_smart(audio_path)\n",
        "    \n",
        "    # 確保符合Whisper要求\n",
        "    waveform, sample_rate = ensure_16khz_for_whisper(waveform, sample_rate)\n",
        "    \n",
        "    return waveform, sample_rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1fc7CEIfKajK",
        "outputId": "3693cd57-14f9-4d2c-fdd9-0d820178e033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ TaiwaneseSTTTTSSystem 類別載入完成\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:14: SyntaxWarning: invalid escape sequence '\\j'\n",
            "<>:86: SyntaxWarning: invalid escape sequence '\\j'\n",
            "<>:14: SyntaxWarning: invalid escape sequence '\\j'\n",
            "<>:86: SyntaxWarning: invalid escape sequence '\\j'\n",
            "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_35064\\1541636484.py:14: SyntaxWarning: invalid escape sequence '\\j'\n",
            "  model_name = \"C:/Users\\johns\\models\\whisper\"\n",
            "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_35064\\1541636484.py:86: SyntaxWarning: invalid escape sequence '\\j'\n",
            "  model_name = \"C:/Users\\johns\\models\\whisper\"\n"
          ]
        }
      ],
      "source": [
        "class TaiwaneseSTTTTSSystem:\n",
        "    def __init__(self):\n",
        "        \"\"\"初始化台語語音轉換系統（ROCm優化版）\"\"\"\n",
        "        self.device = device\n",
        "        #self.setup_stt_model()\n",
        "        #self.setup_tts_model()\n",
        "        self.setup_taiwanese_tools()\n",
        "\n",
        "    def setup_stt_model(self):\n",
        "        \n",
        "        \"\"\"設定台語轉中文的語音辨識模型\"\"\"\n",
        "        try:\n",
        "            # 修正模型名稱\n",
        "            model_name = \"C:/Users\\johns\\models\\whisper\"\n",
        "\n",
        "            self.stt_processor = AutoProcessor.from_pretrained(model_name)\n",
        "            self.stt_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "                model_name,\n",
        "                torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
        "                device_map=\"auto\" if self.device == \"cuda\" else None\n",
        "            )\n",
        "            print(f\"✅ Whisper 載入成功，使用設備：{self.device}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ MR Breeze ASR載入失敗，改用Whisper：{e}\")\n",
        "            # 備用方案：使用Whisper\n",
        "            self.stt_pipe = pipeline(\n",
        "                \"automatic-speech-recognition\",\n",
        "                model=\"openai/whisper-medium\",\n",
        "                device=0 if self.device == \"cuda\" else -1\n",
        "            )\n",
        "            self.stt_model = None\n",
        "\n",
        "    def setup_tts_model(self):\n",
        "        \"\"\"設定中文轉台語的語音合成模型（ROCm優化）\"\"\"\n",
        "        try:\n",
        "            if ChatTTS:\n",
        "                self.chattts = ChatTTS.Chat()\n",
        "\n",
        "                # ROCm環境設定\n",
        "                if self.device == \"cuda\":\n",
        "                    self.chattts.load_models(\n",
        "                        compile=False,\n",
        "                        device=\"cuda\",\n",
        "                        dtype=torch.float16\n",
        "                    )\n",
        "                else:\n",
        "                    self.chattts.load_models(compile=False)\n",
        "\n",
        "                print(\"✅ ChatTTS載入成功\")\n",
        "            else:\n",
        "                raise ImportError(\"ChatTTS未導入\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ ChatTTS載入失敗：{e}\")\n",
        "            self.chattts = None\n",
        "\n",
        "    def setup_taiwanese_tools(self):\n",
        "        \"\"\"設定台灣言語工具\"\"\"\n",
        "        try:\n",
        "            if 語音合成 and 語音辨識:\n",
        "                # 正確實例化類別\n",
        "                self.taiwanese_synthesizer = 語音合成()\n",
        "                self.taiwanese_recognizer = 語音辨識()\n",
        "                print(\"✅ 台灣言語工具載入成功\")\n",
        "            else:\n",
        "                raise ImportError(\"台灣言語工具模組未導入\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 台灣言語工具載入失敗: {e}\")\n",
        "            self.taiwanese_synthesizer = None\n",
        "            self.taiwanese_recognizer = None\n",
        "            \n",
        "\n",
        "    def taiwanese_to_chinese_text(self, audio_file_path, mode):\n",
        "        try:\n",
        "            print(f\"🎤 開始語音辨識: {audio_file_path}\")\n",
        "            \n",
        "            # 處理路徑\n",
        "            \n",
        "            # 載入並確保16kHz採樣率\n",
        "            waveform, sample_rate = torchaudio.load(audio_file_path)\n",
        "            audio, sample_rate = ensure_16khz_for_whisper(waveform, sample_rate)\n",
        "            \n",
        "            print(\"Whisper 語音處理完成\")\n",
        "            if (mode == \"ch\"):\n",
        "                model_name = 'C:/Users/johns/models/MR_breeze'\n",
        "            elif (mode == \"tw\"):\n",
        "                model_name = \"C:/Users\\johns\\models\\whisper\"\n",
        "\n",
        "            pipe = pipeline(\"automatic-speech-recognition\", model = model_name)\n",
        "\n",
        "            result = pipe(audio, generate_kwargs={\"language\": \"zh\", \"task\": \"transcribe\"})\n",
        "            text = result['text']\n",
        "            \n",
        "            print(f\"📝 辨識完成: {text}\")\n",
        "            return text\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ 語音辨識錯誤: {e}\")\n",
        "            return None\n",
        "\n",
        "    #def chinese_to_taiwanese_speech(self, chinese_text):\n",
        "        \n",
        "\n",
        "    def play_audio(self, audio_file):\n",
        "        \"\"\"播放音檔\"\"\"\n",
        "        try:\n",
        "            # 在WSL環境中使用系統播放器\n",
        "            audio_path = convert_windows_path(audio_file)\n",
        "            subprocess.run(['aplay', audio_path], check=True)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 播放音檔錯誤: {e}\")\n",
        "            print(\"💡 提示：在WSL中可能需要安裝音頻播放工具\")\n",
        "\n",
        "    def process_taiwanese_audio_pipeline(self, input_audio_file, mode):\n",
        "        \"\"\"完整的台語音檔處理流程\"\"\"\n",
        "        print(\"🎙️ 開始處理台語音檔...\")\n",
        "\n",
        "        # 步驟1: 台語語音轉中文文字\n",
        "        chinese_text = self.taiwanese_to_chinese_text(input_audio_file, mode)\n",
        "        if chinese_text:\n",
        "            print(f\"📝 辨識結果: {chinese_text}\")\n",
        "            return chinese_text\n",
        "        else:\n",
        "            print(\"❌ 語音辨識失敗\")\n",
        "            return\n",
        "\n",
        "        # 步驟2: 中文文字轉台語語音\n",
        "        '''output_file = self.chinese_to_taiwanese_speech(chinese_text)\n",
        "        if output_file:\n",
        "            print(f\"🔊 語音合成完成: {output_file}\")\n",
        "\n",
        "            # 步驟3: 播放合成的台語語音\n",
        "            self.play_audio(output_file)\n",
        "        else:\n",
        "            print(\"❌ 語音合成失敗\")'''\n",
        "\n",
        "print(\"✅ TaiwaneseSTTTTSSystem 類別載入完成\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 音檔重新採樣支援已加入\n"
          ]
        }
      ],
      "source": [
        "# === 音檔重新採樣支援 ===\n",
        "\n",
        "from torchaudio.transforms import Resample\n",
        "import numpy as np\n",
        "\n",
        "def resample_audio_to_16khz(waveform, original_sample_rate, target_rate=16000):\n",
        "    \"\"\"將音檔重新採樣到16kHz\"\"\"\n",
        "    \n",
        "    if original_sample_rate == target_rate:\n",
        "        print(f\"✅ 採樣率已是 {target_rate}Hz，無需重新採樣\")\n",
        "        return waveform, target_rate\n",
        "    \n",
        "    print(f\"🔄 重新採樣: {original_sample_rate}Hz → {target_rate}Hz\")\n",
        "    \n",
        "    try:\n",
        "        resampler = Resample(orig_freq=original_sample_rate, new_freq=target_rate)\n",
        "        waveform_resampled = resampler(waveform)\n",
        "        print(f\"✅ 重新採樣成功\")\n",
        "        return waveform_resampled, target_rate\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 重新採樣失敗: {e}\")\n",
        "        raise\n",
        "\n",
        "# 修正原有的load_audio_smart函數\n",
        "# original_load_audio_smart = load_audio_smart\n",
        "\n",
        "def load_audio_smart(audio_path, target_sr=16000):\n",
        "    \"\"\"智能載入音檔並重新採樣（修正版）\"\"\"\n",
        "    \n",
        "    # 使用原有的載入函數\n",
        "    waveform, sample_rate = original_load_audio_smart(audio_path)\n",
        "    \n",
        "    # 重新採樣到目標採樣率\n",
        "    if sample_rate != target_sr:\n",
        "        waveform, sample_rate = resample_audio_to_16khz(waveform, sample_rate, target_sr)\n",
        "    \n",
        "    # 確保單聲道\n",
        "    if len(waveform.shape) > 1 and waveform.shape[0] > 1:\n",
        "        print(\"🔄 轉換為單聲道\")\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "    \n",
        "    return waveform, sample_rate\n",
        "\n",
        "print(\"✅ 音檔重新採樣支援已加入\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "438a5763c4d4468fa5bd9f5b78bd3b8e",
            "be0000dca7474df9b51835042828c576",
            "8b9e0c76613a411a865dd888ab570799",
            "9330067ce5544517908cd8bc68f6e3fd",
            "05ec68528da54d508119d317b8d6557a",
            "96f88d4335e842df8a0f41b17a7c41f8",
            "5194ca94c33844faa7ed44814674182e",
            "39f3d14618ec4013ae177d91fb204ca7",
            "b55ed3d7330a4b6f8acf3ed299872c78",
            "5e1a0d56e1924a23bc3d4cc4cd8db80b",
            "8de9aba4e89e4f18a2179a40b3ead0c5",
            "260e6e7ed1904a69ab2f6773fabff6db",
            "b217c47ff524401eb7abc2be5d6e081b"
          ]
        },
        "id": "Le-F-5JGKbTl",
        "outputId": "9fe7720c-605c-4b3b-987f-42148ca4e16f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💡 執行 main() 開始測試系統\n",
            "💡 或執行 system = TaiwaneseSTTTTSSystem() 手動初始化\n",
            "🚀 正在初始化台語語音轉換系統（ROCm版）...\n",
            "❌ 台灣言語工具載入失敗: 台灣言語工具模組未導入\n",
            "🎙️ 開始處理台語音檔...\n",
            "🎤 開始語音辨識: C:/Users/johns/Desktop/project/2025meichu_hackathon/backend/speech_to_text/output.wav\n",
            "🎵 檢查採樣率: 44100Hz\n",
            "⚠️ 採樣率 44100Hz 不符合Whisper要求，重新採樣到16kHz\n",
            "🔄 重新採樣: 44100Hz → 16000Hz\n",
            "✅ 重新採樣成功\n",
            "🔄 轉換為單聲道\n",
            "✅ 音檔準備完成: 採樣率=16000Hz, 形狀=torch.Size([1, 28607])\n",
            "Whisper 語音處理完成\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\johns\\Desktop\\project\\2025meichu_hackathon\\venv\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "We expect a single channel audio input for AutomaticSpeechRecognitionPipeline, got 2. Taking the mean of the channels for mono conversion.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📝 辨識完成: 下\n",
            "📝 辨識結果: 下\n"
          ]
        }
      ],
      "source": [
        "# 使用範例（ROCm優化版）\n",
        "def main():\n",
        "    # 初始化系統\n",
        "    print(\"🚀 正在初始化台語語音轉換系統（ROCm版）...\")\n",
        "    system = TaiwaneseSTTTTSSystem()\n",
        "\n",
        "    # 範例1: 處理台語音檔\n",
        "    #input_audio = \"C:/Users/johns/taiwanese_voice/cv-corpus-22.0-delta-2025-06-20/nan-tw/clips/common_voice_nan-tw_42722929.mp3\"\n",
        "    input_audio = \"C:/Users/johns/Desktop/project/2025meichu_hackathon/backend/speech_to_text/output.wav\"\n",
        "    chinese_text = system.process_taiwanese_audio_pipeline(input_audio, 'ch')\n",
        "    \n",
        "    with open('C:/Users/johns/Desktop/project/2025meichu_hackathon/backend/example.txt', 'w', encoding='utf-8') as file:\n",
        "        file.write(chinese_text)\n",
        "    # 範例2: 直接中文轉台語\n",
        "    '''chinese_text = \"你好，今天天氣很好\"\n",
        "    print(f\"\\n🔄 轉換中文文字: {chinese_text}\")\n",
        "    output_file = system.chinese_to_taiwanese_speech(chinese_text, \"direct_output.wav\")\n",
        "    if output_file:\n",
        "        print(f\"✅ 直接轉換成功: {output_file}\")\n",
        "        system.play_audio(output_file)\n",
        "    else:\n",
        "        print(\"❌ 直接轉換失敗\")'''\n",
        "\n",
        "# 不自動執行，需要手動呼叫\n",
        "print(\"💡 執行 main() 開始測試系統\")\n",
        "print(\"💡 或執行 system = TaiwaneseSTTTTSSystem() 手動初始化\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
