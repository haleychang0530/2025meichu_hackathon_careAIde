{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OrUHVL0_KQxi",
        "outputId": "33f813ab-6b66-4cc3-b363-c9154b303ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ChatTTSå°å…¥æˆåŠŸ\n",
            "âŒ å°ç£è¨€èªå·¥å…·å°å…¥å¤±æ•—: No module named 'è‡ºç£è¨€èªå·¥å…·'\n"
          ]
        }
      ],
      "source": [
        "# ROCmç’°å¢ƒè¨­å®š\n",
        "import os\n",
        "os.environ['HSA_OVERRIDE_GFX_VERSION'] = '10.3.0'  # æ ¹æ“šä½ çš„GPUèª¿æ•´\n",
        "os.environ['HIP_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "# åŸºæœ¬å¥—ä»¶å°å…¥\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import pipeline, AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "import soundfile as sf\n",
        "import subprocess\n",
        "import tempfile\n",
        "from pydub import AudioSegment\n",
        "import librosa\n",
        "\n",
        "try:\n",
        "    import ChatTTS\n",
        "    print(\"âœ… ChatTTSå°å…¥æˆåŠŸ\")\n",
        "except ImportError:\n",
        "    print(\"âŒ ChatTTSæœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install ChatTTS\")\n",
        "    ChatTTS = None\n",
        "\n",
        "\n",
        "# å˜—è©¦å°å…¥å°ç£è¨€èªå·¥å…·\n",
        "try:\n",
        "    from è‡ºç£è¨€èªå·¥å…· import èªéŸ³åˆæˆ\n",
        "    from è‡ºç£è¨€èªå·¥å…· import èªéŸ³è¾¨è­˜\n",
        "    print(\"âœ… å°ç£è¨€èªå·¥å…·å°å…¥æˆåŠŸ\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ å°ç£è¨€èªå·¥å…·å°å…¥å¤±æ•—: {e}\")\n",
        "    èªéŸ³åˆæˆ = None\n",
        "    èªéŸ³è¾¨è­˜ = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "#source venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3DybdAxwKVWG",
        "outputId": "eed33ee3-d435-4357-b59f-740d70b6b74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ROCmç’°å¢ƒæª¢æŸ¥ ===\n",
            "PyTorchç‰ˆæœ¬: 2.8.0+cpu\n",
            "ROCmå¯ç”¨: False\n",
            "==================\n",
            "âš ï¸ ä½¿ç”¨CPUï¼ˆå»ºè­°ä½¿ç”¨GPUåŠ é€Ÿï¼‰\n"
          ]
        }
      ],
      "source": [
        "def check_rocm_environment():\n",
        "    \"\"\"æª¢æŸ¥ROCmç’°å¢ƒ\"\"\"\n",
        "    print(\"=== ROCmç’°å¢ƒæª¢æŸ¥ ===\")\n",
        "    print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
        "    print(f\"ROCmå¯ç”¨: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPUæ•¸é‡: {torch.cuda.device_count()}\")\n",
        "        print(f\"ç•¶å‰GPU: {torch.cuda.current_device()}\")\n",
        "        print(f\"GPUåç¨±: {torch.cuda.get_device_name()}\")\n",
        "    print(\"==================\")\n",
        "\n",
        "def setup_device():\n",
        "    \"\"\"è¨­å®šè¨ˆç®—è¨­å‚™\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "        print(f\"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name()}\")\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "        print(\"âš ï¸ ä½¿ç”¨CPUï¼ˆå»ºè­°ä½¿ç”¨GPUåŠ é€Ÿï¼‰\")\n",
        "\n",
        "    torch.set_default_device(device)\n",
        "    return device\n",
        "\n",
        "# åŸ·è¡Œç’°å¢ƒæª¢æŸ¥\n",
        "check_rocm_environment()\n",
        "device = setup_device()\n",
        "\n",
        "def convert_windows_path(path):\n",
        "    \"\"\"è½‰æ›Windowsè·¯å¾‘ç‚ºWSLè·¯å¾‘\"\"\"\n",
        "    if path.startswith('C:'):\n",
        "        return path.replace('C:', '/mnt/c').replace('\\\\', '/')\n",
        "    return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import librosa\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio.transforms import Resample\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def resample_audio_to_16khz(waveform, original_sample_rate, target_rate=16000):\n",
        "    \"\"\"å°‡éŸ³æª”é‡æ–°æ¡æ¨£åˆ°16kHz\"\"\"\n",
        "    \n",
        "    if original_sample_rate == target_rate:\n",
        "        print(f\"âœ… æ¡æ¨£ç‡å·²æ˜¯ {target_rate}Hzï¼Œç„¡éœ€é‡æ–°æ¡æ¨£\")\n",
        "        return waveform, target_rate\n",
        "    \n",
        "    print(f\"ğŸ”„ é‡æ–°æ¡æ¨£: {original_sample_rate}Hz â†’ {target_rate}Hz\")\n",
        "    \n",
        "    # æ–¹æ³•1: ä½¿ç”¨librosaé‡æ–°æ¡æ¨£ï¼ˆå¦‚æœå¯ç”¨ï¼‰\n",
        "    try:\n",
        "        if librosa:\n",
        "            if len(waveform.shape) > 1 and waveform.shape[0] > 1:\n",
        "                # å¤šè²é“è™•ç†\n",
        "                resampled = []\n",
        "                for channel in waveform:\n",
        "                    channel_resampled = librosa.resample(\n",
        "                        channel.numpy(), \n",
        "                        orig_sr=original_sample_rate, \n",
        "                        target_sr=target_rate\n",
        "                    )\n",
        "                    resampled.append(channel_resampled)\n",
        "                waveform_resampled = torch.from_numpy(np.array(resampled))\n",
        "            else:\n",
        "                # å–®è²é“è™•ç†\n",
        "                waveform_np = waveform.squeeze().numpy()\n",
        "                waveform_resampled_np = librosa.resample(\n",
        "                    waveform_np, \n",
        "                    orig_sr=original_sample_rate, \n",
        "                    target_sr=target_rate\n",
        "                )\n",
        "                waveform_resampled = torch.from_numpy(waveform_resampled_np).unsqueeze(0)\n",
        "            \n",
        "            print(f\"âœ… librosaé‡æ–°æ¡æ¨£æˆåŠŸ\")\n",
        "            return waveform_resampled, target_rate\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ librosaé‡æ–°æ¡æ¨£å¤±æ•—: {e}\")\n",
        "    \n",
        "    # æ–¹æ³•2: ä½¿ç”¨torchaudioé‡æ–°æ¡æ¨£\n",
        "    try:\n",
        "        resampler = Resample(orig_freq=original_sample_rate, new_freq=target_rate)\n",
        "        waveform_resampled = resampler(waveform)\n",
        "        print(f\"âœ… torchaudioé‡æ–°æ¡æ¨£æˆåŠŸ\")\n",
        "        return waveform_resampled, target_rate\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ torchaudioé‡æ–°æ¡æ¨£å¤±æ•—: {e}\")\n",
        "    \n",
        "    # æ–¹æ³•3: ä½¿ç”¨ffmpegé‡æ–°æ¡æ¨£\n",
        "    try:\n",
        "        import tempfile\n",
        "        import subprocess\n",
        "        \n",
        "        # å„²å­˜åŸå§‹éŸ³æª”\n",
        "        temp_input = tempfile.mktemp(suffix='.wav')\n",
        "        torchaudio.save(temp_input, waveform, original_sample_rate)\n",
        "        \n",
        "        # ä½¿ç”¨ffmpegé‡æ–°æ¡æ¨£\n",
        "        temp_output = tempfile.mktemp(suffix='.wav')\n",
        "        subprocess.run([\n",
        "            'ffmpeg', '-i', temp_input, \n",
        "            '-ar', str(target_rate), \n",
        "            '-ac', '1',  # è½‰ç‚ºå–®è²é“\n",
        "            temp_output, '-y'\n",
        "        ], check=True, capture_output=True)\n",
        "        \n",
        "        # è¼‰å…¥é‡æ–°æ¡æ¨£å¾Œçš„éŸ³æª”\n",
        "        waveform_resampled, _ = torchaudio.load(temp_output)\n",
        "        \n",
        "        # æ¸…ç†æš«å­˜æª”\n",
        "        os.remove(temp_input)\n",
        "        os.remove(temp_output)\n",
        "        \n",
        "        print(f\"âœ… ffmpegé‡æ–°æ¡æ¨£æˆåŠŸ\")\n",
        "        return waveform_resampled, target_rate\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ffmpegé‡æ–°æ¡æ¨£å¤±æ•—: {e}\")\n",
        "    \n",
        "    raise RuntimeError(f\"ç„¡æ³•é‡æ–°æ¡æ¨£éŸ³æª”å¾ {original_sample_rate}Hz åˆ° {target_rate}Hz\")\n",
        "\n",
        "\n",
        "def ensure_16khz_for_whisper(waveform, sample_rate):\n",
        "    \"\"\"ç¢ºä¿éŸ³æª”ç¬¦åˆWhisperçš„16kHzè¦æ±‚\"\"\"\n",
        "    \n",
        "    print(f\"ğŸµ æª¢æŸ¥æ¡æ¨£ç‡: {sample_rate}Hz\")\n",
        "    \n",
        "    # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°æ¡æ¨£\n",
        "    if sample_rate != 16000:\n",
        "        print(f\"âš ï¸ æ¡æ¨£ç‡ {sample_rate}Hz ä¸ç¬¦åˆWhisperè¦æ±‚ï¼Œé‡æ–°æ¡æ¨£åˆ°16kHz\")\n",
        "        waveform, sample_rate = resample_audio_to_16khz(waveform, sample_rate)\n",
        "    \n",
        "    # ç¢ºä¿æ˜¯å–®è²é“\n",
        "    if len(waveform.shape) > 1 and waveform.shape[0] > 1:\n",
        "        print(\"ğŸ”„ è½‰æ›ç‚ºå–®è²é“\")\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "    \n",
        "    print(f\"âœ… éŸ³æª”æº–å‚™å®Œæˆ: æ¡æ¨£ç‡={sample_rate}Hz, å½¢ç‹€={waveform.shape}\")\n",
        "    return waveform, sample_rate\n",
        "\n",
        "def load_audio_for_whisper(audio_path):\n",
        "    \"\"\"å°ˆç‚ºWhisperæ¨¡å‹è¼‰å…¥å’Œé è™•ç†éŸ³æª”\"\"\"\n",
        "    \n",
        "    print(f\"ğŸµ ç‚ºWhisperè¼‰å…¥éŸ³æª”: {audio_path}\")\n",
        "    \n",
        "    # ä½¿ç”¨ä¹‹å‰å»ºç«‹çš„å¤šé‡å‚™æ´è¼‰å…¥å‡½æ•¸\n",
        "    waveform, sample_rate = load_audio_smart(audio_path)\n",
        "    \n",
        "    # ç¢ºä¿ç¬¦åˆWhisperè¦æ±‚\n",
        "    waveform, sample_rate = ensure_16khz_for_whisper(waveform, sample_rate)\n",
        "    \n",
        "    return waveform, sample_rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1fc7CEIfKajK",
        "outputId": "3693cd57-14f9-4d2c-fdd9-0d820178e033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… TaiwaneseSTTTTSSystem é¡åˆ¥è¼‰å…¥å®Œæˆ\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:14: SyntaxWarning: invalid escape sequence '\\j'\n",
            "<>:86: SyntaxWarning: invalid escape sequence '\\j'\n",
            "<>:14: SyntaxWarning: invalid escape sequence '\\j'\n",
            "<>:86: SyntaxWarning: invalid escape sequence '\\j'\n",
            "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_35064\\1541636484.py:14: SyntaxWarning: invalid escape sequence '\\j'\n",
            "  model_name = \"C:/Users\\johns\\models\\whisper\"\n",
            "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_35064\\1541636484.py:86: SyntaxWarning: invalid escape sequence '\\j'\n",
            "  model_name = \"C:/Users\\johns\\models\\whisper\"\n"
          ]
        }
      ],
      "source": [
        "class TaiwaneseSTTTTSSystem:\n",
        "    def __init__(self):\n",
        "        \"\"\"åˆå§‹åŒ–å°èªèªéŸ³è½‰æ›ç³»çµ±ï¼ˆROCmå„ªåŒ–ç‰ˆï¼‰\"\"\"\n",
        "        self.device = device\n",
        "        #self.setup_stt_model()\n",
        "        #self.setup_tts_model()\n",
        "        self.setup_taiwanese_tools()\n",
        "\n",
        "    def setup_stt_model(self):\n",
        "        \n",
        "        \"\"\"è¨­å®šå°èªè½‰ä¸­æ–‡çš„èªéŸ³è¾¨è­˜æ¨¡å‹\"\"\"\n",
        "        try:\n",
        "            # ä¿®æ­£æ¨¡å‹åç¨±\n",
        "            model_name = \"C:/Users\\johns\\models\\whisper\"\n",
        "\n",
        "            self.stt_processor = AutoProcessor.from_pretrained(model_name)\n",
        "            self.stt_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "                model_name,\n",
        "                torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
        "                device_map=\"auto\" if self.device == \"cuda\" else None\n",
        "            )\n",
        "            print(f\"âœ… Whisper è¼‰å…¥æˆåŠŸï¼Œä½¿ç”¨è¨­å‚™ï¼š{self.device}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ MR Breeze ASRè¼‰å…¥å¤±æ•—ï¼Œæ”¹ç”¨Whisperï¼š{e}\")\n",
        "            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨Whisper\n",
        "            self.stt_pipe = pipeline(\n",
        "                \"automatic-speech-recognition\",\n",
        "                model=\"openai/whisper-medium\",\n",
        "                device=0 if self.device == \"cuda\" else -1\n",
        "            )\n",
        "            self.stt_model = None\n",
        "\n",
        "    def setup_tts_model(self):\n",
        "        \"\"\"è¨­å®šä¸­æ–‡è½‰å°èªçš„èªéŸ³åˆæˆæ¨¡å‹ï¼ˆROCmå„ªåŒ–ï¼‰\"\"\"\n",
        "        try:\n",
        "            if ChatTTS:\n",
        "                self.chattts = ChatTTS.Chat()\n",
        "\n",
        "                # ROCmç’°å¢ƒè¨­å®š\n",
        "                if self.device == \"cuda\":\n",
        "                    self.chattts.load_models(\n",
        "                        compile=False,\n",
        "                        device=\"cuda\",\n",
        "                        dtype=torch.float16\n",
        "                    )\n",
        "                else:\n",
        "                    self.chattts.load_models(compile=False)\n",
        "\n",
        "                print(\"âœ… ChatTTSè¼‰å…¥æˆåŠŸ\")\n",
        "            else:\n",
        "                raise ImportError(\"ChatTTSæœªå°å…¥\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ChatTTSè¼‰å…¥å¤±æ•—ï¼š{e}\")\n",
        "            self.chattts = None\n",
        "\n",
        "    def setup_taiwanese_tools(self):\n",
        "        \"\"\"è¨­å®šå°ç£è¨€èªå·¥å…·\"\"\"\n",
        "        try:\n",
        "            if èªéŸ³åˆæˆ and èªéŸ³è¾¨è­˜:\n",
        "                # æ­£ç¢ºå¯¦ä¾‹åŒ–é¡åˆ¥\n",
        "                self.taiwanese_synthesizer = èªéŸ³åˆæˆ()\n",
        "                self.taiwanese_recognizer = èªéŸ³è¾¨è­˜()\n",
        "                print(\"âœ… å°ç£è¨€èªå·¥å…·è¼‰å…¥æˆåŠŸ\")\n",
        "            else:\n",
        "                raise ImportError(\"å°ç£è¨€èªå·¥å…·æ¨¡çµ„æœªå°å…¥\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ å°ç£è¨€èªå·¥å…·è¼‰å…¥å¤±æ•—: {e}\")\n",
        "            self.taiwanese_synthesizer = None\n",
        "            self.taiwanese_recognizer = None\n",
        "            \n",
        "\n",
        "    def taiwanese_to_chinese_text(self, audio_file_path, mode):\n",
        "        try:\n",
        "            print(f\"ğŸ¤ é–‹å§‹èªéŸ³è¾¨è­˜: {audio_file_path}\")\n",
        "            \n",
        "            # è™•ç†è·¯å¾‘\n",
        "            \n",
        "            # è¼‰å…¥ä¸¦ç¢ºä¿16kHzæ¡æ¨£ç‡\n",
        "            waveform, sample_rate = torchaudio.load(audio_file_path)\n",
        "            audio, sample_rate = ensure_16khz_for_whisper(waveform, sample_rate)\n",
        "            \n",
        "            print(\"Whisper èªéŸ³è™•ç†å®Œæˆ\")\n",
        "            if (mode == \"ch\"):\n",
        "                model_name = 'C:/Users/johns/models/MR_breeze'\n",
        "            elif (mode == \"tw\"):\n",
        "                model_name = \"C:/Users\\johns\\models\\whisper\"\n",
        "\n",
        "            pipe = pipeline(\"automatic-speech-recognition\", model = model_name)\n",
        "\n",
        "            result = pipe(audio, generate_kwargs={\"language\": \"zh\", \"task\": \"transcribe\"})\n",
        "            text = result['text']\n",
        "            \n",
        "            print(f\"ğŸ“ è¾¨è­˜å®Œæˆ: {text}\")\n",
        "            return text\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ èªéŸ³è¾¨è­˜éŒ¯èª¤: {e}\")\n",
        "            return None\n",
        "\n",
        "    #def chinese_to_taiwanese_speech(self, chinese_text):\n",
        "        \n",
        "\n",
        "    def play_audio(self, audio_file):\n",
        "        \"\"\"æ’­æ”¾éŸ³æª”\"\"\"\n",
        "        try:\n",
        "            # åœ¨WSLç’°å¢ƒä¸­ä½¿ç”¨ç³»çµ±æ’­æ”¾å™¨\n",
        "            audio_path = convert_windows_path(audio_file)\n",
        "            subprocess.run(['aplay', audio_path], check=True)\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ æ’­æ”¾éŸ³æª”éŒ¯èª¤: {e}\")\n",
        "            print(\"ğŸ’¡ æç¤ºï¼šåœ¨WSLä¸­å¯èƒ½éœ€è¦å®‰è£éŸ³é »æ’­æ”¾å·¥å…·\")\n",
        "\n",
        "    def process_taiwanese_audio_pipeline(self, input_audio_file, mode):\n",
        "        \"\"\"å®Œæ•´çš„å°èªéŸ³æª”è™•ç†æµç¨‹\"\"\"\n",
        "        print(\"ğŸ™ï¸ é–‹å§‹è™•ç†å°èªéŸ³æª”...\")\n",
        "\n",
        "        # æ­¥é©Ÿ1: å°èªèªéŸ³è½‰ä¸­æ–‡æ–‡å­—\n",
        "        chinese_text = self.taiwanese_to_chinese_text(input_audio_file, mode)\n",
        "        if chinese_text:\n",
        "            print(f\"ğŸ“ è¾¨è­˜çµæœ: {chinese_text}\")\n",
        "            return chinese_text\n",
        "        else:\n",
        "            print(\"âŒ èªéŸ³è¾¨è­˜å¤±æ•—\")\n",
        "            return\n",
        "\n",
        "        # æ­¥é©Ÿ2: ä¸­æ–‡æ–‡å­—è½‰å°èªèªéŸ³\n",
        "        '''output_file = self.chinese_to_taiwanese_speech(chinese_text)\n",
        "        if output_file:\n",
        "            print(f\"ğŸ”Š èªéŸ³åˆæˆå®Œæˆ: {output_file}\")\n",
        "\n",
        "            # æ­¥é©Ÿ3: æ’­æ”¾åˆæˆçš„å°èªèªéŸ³\n",
        "            self.play_audio(output_file)\n",
        "        else:\n",
        "            print(\"âŒ èªéŸ³åˆæˆå¤±æ•—\")'''\n",
        "\n",
        "print(\"âœ… TaiwaneseSTTTTSSystem é¡åˆ¥è¼‰å…¥å®Œæˆ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… éŸ³æª”é‡æ–°æ¡æ¨£æ”¯æ´å·²åŠ å…¥\n"
          ]
        }
      ],
      "source": [
        "# === éŸ³æª”é‡æ–°æ¡æ¨£æ”¯æ´ ===\n",
        "\n",
        "from torchaudio.transforms import Resample\n",
        "import numpy as np\n",
        "\n",
        "def resample_audio_to_16khz(waveform, original_sample_rate, target_rate=16000):\n",
        "    \"\"\"å°‡éŸ³æª”é‡æ–°æ¡æ¨£åˆ°16kHz\"\"\"\n",
        "    \n",
        "    if original_sample_rate == target_rate:\n",
        "        print(f\"âœ… æ¡æ¨£ç‡å·²æ˜¯ {target_rate}Hzï¼Œç„¡éœ€é‡æ–°æ¡æ¨£\")\n",
        "        return waveform, target_rate\n",
        "    \n",
        "    print(f\"ğŸ”„ é‡æ–°æ¡æ¨£: {original_sample_rate}Hz â†’ {target_rate}Hz\")\n",
        "    \n",
        "    try:\n",
        "        resampler = Resample(orig_freq=original_sample_rate, new_freq=target_rate)\n",
        "        waveform_resampled = resampler(waveform)\n",
        "        print(f\"âœ… é‡æ–°æ¡æ¨£æˆåŠŸ\")\n",
        "        return waveform_resampled, target_rate\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ é‡æ–°æ¡æ¨£å¤±æ•—: {e}\")\n",
        "        raise\n",
        "\n",
        "# ä¿®æ­£åŸæœ‰çš„load_audio_smartå‡½æ•¸\n",
        "# original_load_audio_smart = load_audio_smart\n",
        "\n",
        "def load_audio_smart(audio_path, target_sr=16000):\n",
        "    \"\"\"æ™ºèƒ½è¼‰å…¥éŸ³æª”ä¸¦é‡æ–°æ¡æ¨£ï¼ˆä¿®æ­£ç‰ˆï¼‰\"\"\"\n",
        "    \n",
        "    # ä½¿ç”¨åŸæœ‰çš„è¼‰å…¥å‡½æ•¸\n",
        "    waveform, sample_rate = original_load_audio_smart(audio_path)\n",
        "    \n",
        "    # é‡æ–°æ¡æ¨£åˆ°ç›®æ¨™æ¡æ¨£ç‡\n",
        "    if sample_rate != target_sr:\n",
        "        waveform, sample_rate = resample_audio_to_16khz(waveform, sample_rate, target_sr)\n",
        "    \n",
        "    # ç¢ºä¿å–®è²é“\n",
        "    if len(waveform.shape) > 1 and waveform.shape[0] > 1:\n",
        "        print(\"ğŸ”„ è½‰æ›ç‚ºå–®è²é“\")\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "    \n",
        "    return waveform, sample_rate\n",
        "\n",
        "print(\"âœ… éŸ³æª”é‡æ–°æ¡æ¨£æ”¯æ´å·²åŠ å…¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "438a5763c4d4468fa5bd9f5b78bd3b8e",
            "be0000dca7474df9b51835042828c576",
            "8b9e0c76613a411a865dd888ab570799",
            "9330067ce5544517908cd8bc68f6e3fd",
            "05ec68528da54d508119d317b8d6557a",
            "96f88d4335e842df8a0f41b17a7c41f8",
            "5194ca94c33844faa7ed44814674182e",
            "39f3d14618ec4013ae177d91fb204ca7",
            "b55ed3d7330a4b6f8acf3ed299872c78",
            "5e1a0d56e1924a23bc3d4cc4cd8db80b",
            "8de9aba4e89e4f18a2179a40b3ead0c5",
            "260e6e7ed1904a69ab2f6773fabff6db",
            "b217c47ff524401eb7abc2be5d6e081b"
          ]
        },
        "id": "Le-F-5JGKbTl",
        "outputId": "9fe7720c-605c-4b3b-987f-42148ca4e16f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ’¡ åŸ·è¡Œ main() é–‹å§‹æ¸¬è©¦ç³»çµ±\n",
            "ğŸ’¡ æˆ–åŸ·è¡Œ system = TaiwaneseSTTTTSSystem() æ‰‹å‹•åˆå§‹åŒ–\n",
            "ğŸš€ æ­£åœ¨åˆå§‹åŒ–å°èªèªéŸ³è½‰æ›ç³»çµ±ï¼ˆROCmç‰ˆï¼‰...\n",
            "âŒ å°ç£è¨€èªå·¥å…·è¼‰å…¥å¤±æ•—: å°ç£è¨€èªå·¥å…·æ¨¡çµ„æœªå°å…¥\n",
            "ğŸ™ï¸ é–‹å§‹è™•ç†å°èªéŸ³æª”...\n",
            "ğŸ¤ é–‹å§‹èªéŸ³è¾¨è­˜: C:/Users/johns/Desktop/project/2025meichu_hackathon/backend/speech_to_text/output.wav\n",
            "ğŸµ æª¢æŸ¥æ¡æ¨£ç‡: 44100Hz\n",
            "âš ï¸ æ¡æ¨£ç‡ 44100Hz ä¸ç¬¦åˆWhisperè¦æ±‚ï¼Œé‡æ–°æ¡æ¨£åˆ°16kHz\n",
            "ğŸ”„ é‡æ–°æ¡æ¨£: 44100Hz â†’ 16000Hz\n",
            "âœ… é‡æ–°æ¡æ¨£æˆåŠŸ\n",
            "ğŸ”„ è½‰æ›ç‚ºå–®è²é“\n",
            "âœ… éŸ³æª”æº–å‚™å®Œæˆ: æ¡æ¨£ç‡=16000Hz, å½¢ç‹€=torch.Size([1, 28607])\n",
            "Whisper èªéŸ³è™•ç†å®Œæˆ\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\johns\\Desktop\\project\\2025meichu_hackathon\\venv\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "We expect a single channel audio input for AutomaticSpeechRecognitionPipeline, got 2. Taking the mean of the channels for mono conversion.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ è¾¨è­˜å®Œæˆ: ä¸‹\n",
            "ğŸ“ è¾¨è­˜çµæœ: ä¸‹\n"
          ]
        }
      ],
      "source": [
        "# ä½¿ç”¨ç¯„ä¾‹ï¼ˆROCmå„ªåŒ–ç‰ˆï¼‰\n",
        "def main():\n",
        "    # åˆå§‹åŒ–ç³»çµ±\n",
        "    print(\"ğŸš€ æ­£åœ¨åˆå§‹åŒ–å°èªèªéŸ³è½‰æ›ç³»çµ±ï¼ˆROCmç‰ˆï¼‰...\")\n",
        "    system = TaiwaneseSTTTTSSystem()\n",
        "\n",
        "    # ç¯„ä¾‹1: è™•ç†å°èªéŸ³æª”\n",
        "    #input_audio = \"C:/Users/johns/taiwanese_voice/cv-corpus-22.0-delta-2025-06-20/nan-tw/clips/common_voice_nan-tw_42722929.mp3\"\n",
        "    input_audio = \"C:/Users/johns/Desktop/project/2025meichu_hackathon/backend/speech_to_text/output.wav\"\n",
        "    chinese_text = system.process_taiwanese_audio_pipeline(input_audio, 'ch')\n",
        "    \n",
        "    with open('C:/Users/johns/Desktop/project/2025meichu_hackathon/backend/example.txt', 'w', encoding='utf-8') as file:\n",
        "        file.write(chinese_text)\n",
        "    # ç¯„ä¾‹2: ç›´æ¥ä¸­æ–‡è½‰å°èª\n",
        "    '''chinese_text = \"ä½ å¥½ï¼Œä»Šå¤©å¤©æ°£å¾ˆå¥½\"\n",
        "    print(f\"\\nğŸ”„ è½‰æ›ä¸­æ–‡æ–‡å­—: {chinese_text}\")\n",
        "    output_file = system.chinese_to_taiwanese_speech(chinese_text, \"direct_output.wav\")\n",
        "    if output_file:\n",
        "        print(f\"âœ… ç›´æ¥è½‰æ›æˆåŠŸ: {output_file}\")\n",
        "        system.play_audio(output_file)\n",
        "    else:\n",
        "        print(\"âŒ ç›´æ¥è½‰æ›å¤±æ•—\")'''\n",
        "\n",
        "# ä¸è‡ªå‹•åŸ·è¡Œï¼Œéœ€è¦æ‰‹å‹•å‘¼å«\n",
        "print(\"ğŸ’¡ åŸ·è¡Œ main() é–‹å§‹æ¸¬è©¦ç³»çµ±\")\n",
        "print(\"ğŸ’¡ æˆ–åŸ·è¡Œ system = TaiwaneseSTTTTSSystem() æ‰‹å‹•åˆå§‹åŒ–\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
